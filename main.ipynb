{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOITg9RQGMUlYTo7bUbdecK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96b2f5e803ca41759789b63ba24e6199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f801b4d6df914debb54a0bd2bfa0e1a2",
              "IPY_MODEL_80fb6f15bfae49aea26d0965982640ff",
              "IPY_MODEL_30753cd0fef94540b552019ad5657d0d"
            ],
            "layout": "IPY_MODEL_2933386da8d04a56bbe89dd2b9cd2914"
          }
        },
        "f801b4d6df914debb54a0bd2bfa0e1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55b4a41ecf34201b996eeb0adf22d9b",
            "placeholder": "​",
            "style": "IPY_MODEL_3f45fa12bad24edf970a099d4f2aa13b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "80fb6f15bfae49aea26d0965982640ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_391921d1301649e39f6c321fe8c29a74",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ed04c0b886041f39642d32094fdc346",
            "value": 48
          }
        },
        "30753cd0fef94540b552019ad5657d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f954792ea44b16be644a280d80aa54",
            "placeholder": "​",
            "style": "IPY_MODEL_af171294d9294ecba5bad1e2becf46e7",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.74kB/s]"
          }
        },
        "2933386da8d04a56bbe89dd2b9cd2914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55b4a41ecf34201b996eeb0adf22d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f45fa12bad24edf970a099d4f2aa13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "391921d1301649e39f6c321fe8c29a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed04c0b886041f39642d32094fdc346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92f954792ea44b16be644a280d80aa54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af171294d9294ecba5bad1e2becf46e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff8c60cb69f493183d0451991e1393a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b1a23709339458e83fa0b4b41f293f6",
              "IPY_MODEL_aa1fd8a2bcbb4cf28d773a8a93eae0ca",
              "IPY_MODEL_4108d0244c0941358d6b5136d4841300"
            ],
            "layout": "IPY_MODEL_fb865b8579ed43fc85301eb438b99727"
          }
        },
        "9b1a23709339458e83fa0b4b41f293f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94978d11cb9e435aa4d953f8156e815b",
            "placeholder": "​",
            "style": "IPY_MODEL_4257c14f27e841f393ebd500a599a291",
            "value": "vocab.txt: 100%"
          }
        },
        "aa1fd8a2bcbb4cf28d773a8a93eae0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3796a750110458e9daa16813bd0ef85",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acd64cd2b0e94e2e8b4af995b77e1b7c",
            "value": 231508
          }
        },
        "4108d0244c0941358d6b5136d4841300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ca5543aebb47ef931900f03c0f248e",
            "placeholder": "​",
            "style": "IPY_MODEL_cf3728f2593f40559f3c1cf753872b07",
            "value": " 232k/232k [00:00&lt;00:00, 1.71MB/s]"
          }
        },
        "fb865b8579ed43fc85301eb438b99727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94978d11cb9e435aa4d953f8156e815b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4257c14f27e841f393ebd500a599a291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3796a750110458e9daa16813bd0ef85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd64cd2b0e94e2e8b4af995b77e1b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ca5543aebb47ef931900f03c0f248e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3728f2593f40559f3c1cf753872b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faa1515b1bb64fc380efbde3a6636f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_494aea797c804d58b755c154041266d2",
              "IPY_MODEL_b8fe8dbe9c07486d9363b0e7901ad488",
              "IPY_MODEL_554bb9dda83e49d7bab5ccdb788bad5b"
            ],
            "layout": "IPY_MODEL_181b529bee7e406d91008a8b00be2b11"
          }
        },
        "494aea797c804d58b755c154041266d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37ffdc534b5b4571a6242bfc01197293",
            "placeholder": "​",
            "style": "IPY_MODEL_bb372f5f6ab7404ebf8347f426a0d425",
            "value": "tokenizer.json: 100%"
          }
        },
        "b8fe8dbe9c07486d9363b0e7901ad488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609331d287244e148f5e6dfd0f8cc0bd",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b6db2a4d389419f8a388cad159c3974",
            "value": 466062
          }
        },
        "554bb9dda83e49d7bab5ccdb788bad5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9ff3f3b6fd4a6d91c2bdff8901fda3",
            "placeholder": "​",
            "style": "IPY_MODEL_6204344e6dc44d58910a11141ef670cf",
            "value": " 466k/466k [00:00&lt;00:00, 7.04MB/s]"
          }
        },
        "181b529bee7e406d91008a8b00be2b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ffdc534b5b4571a6242bfc01197293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb372f5f6ab7404ebf8347f426a0d425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609331d287244e148f5e6dfd0f8cc0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6db2a4d389419f8a388cad159c3974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b9ff3f3b6fd4a6d91c2bdff8901fda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6204344e6dc44d58910a11141ef670cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891aca45ff79466a8b74c02623ff7a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_238429be4bca4412ad1ecdc4e24cc932",
              "IPY_MODEL_33b02c54be874e4f946b6475e70ef919",
              "IPY_MODEL_beba626280844ea299b9fb8f71140073"
            ],
            "layout": "IPY_MODEL_c526e8a26e4843d48bf533f139954496"
          }
        },
        "238429be4bca4412ad1ecdc4e24cc932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ce200f46774d15a74b8af8596a1a47",
            "placeholder": "​",
            "style": "IPY_MODEL_5e09b9ce28884a2d964318a3332771a1",
            "value": "config.json: 100%"
          }
        },
        "33b02c54be874e4f946b6475e70ef919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d32420829e475484ae1b8e5385fa0c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb015241db954de5970ab4b30625fd8a",
            "value": 570
          }
        },
        "beba626280844ea299b9fb8f71140073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26df35f67ef74bb1b473571789a2851b",
            "placeholder": "​",
            "style": "IPY_MODEL_a51ed2dc702946038900376d32a898a9",
            "value": " 570/570 [00:00&lt;00:00, 36.5kB/s]"
          }
        },
        "c526e8a26e4843d48bf533f139954496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ce200f46774d15a74b8af8596a1a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e09b9ce28884a2d964318a3332771a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00d32420829e475484ae1b8e5385fa0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb015241db954de5970ab4b30625fd8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26df35f67ef74bb1b473571789a2851b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51ed2dc702946038900376d32a898a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirgh8080/My-SLFEND/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULYbizmj85N-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV file\n",
        "def load_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Inspect the data\n",
        "file_path = '/content/Fake_Real_Data.csv'\n",
        "df = load_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmPh85Lt9Gmq",
        "outputId": "8f8082bd-e1bf-43fd-c8ca-df5b51f196df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text label\n",
            "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
            "1  U.S. conservative leader optimistic of common ...  Real\n",
            "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
            "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
            "4  Democrats say Trump agrees to work on immigrat...  Real\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9900 entries, 0 to 9899\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    9900 non-null   object\n",
            " 1   label   9900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 154.8+ KB\n",
            "None\n",
            "(9900, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessing function\n",
        "def preprocess_data(df, text_column, label_column):\n",
        "    # Drop any rows with missing values\n",
        "    df = df.dropna(subset=[text_column, label_column])\n",
        "\n",
        "    # Ensure labels are binary (0 or 1)\n",
        "    df[label_column] = df[label_column].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "    # Extract texts and labels\n",
        "    texts = df[text_column].tolist()\n",
        "    labels = df[label_column].tolist()\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "# Preprocess the data\n",
        "text_column = 'Text'\n",
        "label_column = 'label'\n",
        "texts, labels = preprocess_data(df, text_column, label_column)\n",
        "\n",
        "print(f'Number of texts: {len(texts)}')\n",
        "print(f'Number of labels: {len(labels)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdCYMG60y_bY",
        "outputId": "f7b60537-237b-45bc-c053-a222d7378845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts: 9900\n",
            "Number of labels: 9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.float)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "YTjKVUgP-gMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_len = 170\n",
        "\n",
        "train_texts, train_labels = texts[:int(0.8*len(texts))], labels[:int(0.8*len(labels))]\n",
        "val_texts, val_labels = texts[int(0.8*len(texts)):int(0.9*len(texts))], labels[int(0.8*len(labels)):int(0.9*len(labels))]\n",
        "test_texts, test_labels = texts[int(0.9*len(texts)):], labels[int(0.9*len(labels)):]\n",
        "\n",
        "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_len)\n",
        "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_len)\n",
        "test_dataset = NewsDataset(test_texts, test_labels, tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "192PfiBZ-233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "96b2f5e803ca41759789b63ba24e6199",
            "f801b4d6df914debb54a0bd2bfa0e1a2",
            "80fb6f15bfae49aea26d0965982640ff",
            "30753cd0fef94540b552019ad5657d0d",
            "2933386da8d04a56bbe89dd2b9cd2914",
            "f55b4a41ecf34201b996eeb0adf22d9b",
            "3f45fa12bad24edf970a099d4f2aa13b",
            "391921d1301649e39f6c321fe8c29a74",
            "3ed04c0b886041f39642d32094fdc346",
            "92f954792ea44b16be644a280d80aa54",
            "af171294d9294ecba5bad1e2becf46e7",
            "3ff8c60cb69f493183d0451991e1393a",
            "9b1a23709339458e83fa0b4b41f293f6",
            "aa1fd8a2bcbb4cf28d773a8a93eae0ca",
            "4108d0244c0941358d6b5136d4841300",
            "fb865b8579ed43fc85301eb438b99727",
            "94978d11cb9e435aa4d953f8156e815b",
            "4257c14f27e841f393ebd500a599a291",
            "f3796a750110458e9daa16813bd0ef85",
            "acd64cd2b0e94e2e8b4af995b77e1b7c",
            "f4ca5543aebb47ef931900f03c0f248e",
            "cf3728f2593f40559f3c1cf753872b07",
            "faa1515b1bb64fc380efbde3a6636f07",
            "494aea797c804d58b755c154041266d2",
            "b8fe8dbe9c07486d9363b0e7901ad488",
            "554bb9dda83e49d7bab5ccdb788bad5b",
            "181b529bee7e406d91008a8b00be2b11",
            "37ffdc534b5b4571a6242bfc01197293",
            "bb372f5f6ab7404ebf8347f426a0d425",
            "609331d287244e148f5e6dfd0f8cc0bd",
            "9b6db2a4d389419f8a388cad159c3974",
            "1b9ff3f3b6fd4a6d91c2bdff8901fda3",
            "6204344e6dc44d58910a11141ef670cf",
            "891aca45ff79466a8b74c02623ff7a74",
            "238429be4bca4412ad1ecdc4e24cc932",
            "33b02c54be874e4f946b6475e70ef919",
            "beba626280844ea299b9fb8f71140073",
            "c526e8a26e4843d48bf533f139954496",
            "63ce200f46774d15a74b8af8596a1a47",
            "5e09b9ce28884a2d964318a3332771a1",
            "00d32420829e475484ae1b8e5385fa0c",
            "eb015241db954de5970ab4b30625fd8a",
            "26df35f67ef74bb1b473571789a2851b",
            "a51ed2dc702946038900376d32a898a9"
          ]
        },
        "outputId": "8d48413c-c435-4dc7-d305-3a1c25fb86b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96b2f5e803ca41759789b63ba24e6199"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff8c60cb69f493183d0451991e1393a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faa1515b1bb64fc380efbde3a6636f07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "891aca45ff79466a8b74c02623ff7a74"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load CSV file\n",
        "def load_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(df, text_column, label_column):\n",
        "    df = df.dropna(subset=[text_column, label_column])\n",
        "    df[label_column] = df[label_column].apply(lambda x: 1 if x == 'Real' else 0)\n",
        "    texts = df[text_column].tolist()\n",
        "    labels = df[label_column].tolist()\n",
        "    return texts, labels\n",
        "\n",
        "# Define dataset class\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Define model components\n",
        "class BertEmbedding(nn.Module):\n",
        "    def __init__(self, bert_model_name):\n",
        "        super(BertEmbedding, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "class LeapGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LeapGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRUCell(input_size, hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2 + input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            ht = self.gru(x[:, t, :], h)\n",
        "            context = torch.cat([h, ht, x[:, t, :]], dim=-1)  # Concatenate h, ht, and x[:, t, :]\n",
        "            pi = self.mlp(context)\n",
        "            skip_prob = pi[:, 1]\n",
        "\n",
        "            if skip_prob.mean() >= 0.5:\n",
        "                h = ht\n",
        "            outputs.append(h)\n",
        "\n",
        "        outputs = torch.stack(outputs, dim=1)\n",
        "        return outputs\n",
        "\n",
        "class MembershipFunction(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MembershipFunction, self).__init__()\n",
        "        self.leap_gru = LeapGRU(input_size, hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 9),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        leap_gru_output = self.leap_gru(x)\n",
        "        h = leap_gru_output[:, -1, :]  # Use the last hidden state\n",
        "        g = self.mlp(h)\n",
        "        return g\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.conv2 = nn.Conv2d(1, 100, (4, input_size))\n",
        "        self.conv3 = nn.Conv2d(1, 100, (5, input_size))\n",
        "        self.fc = nn.Linear(300, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x1 = F.relu(self.conv1(x)).squeeze(3)\n",
        "        x2 = F.relu(self.conv2(x)).squeeze(3)\n",
        "        x3 = F.relu(self.conv3(x)).squeeze(3)\n",
        "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "        x = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n",
        "\n",
        "class DCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.conv2 = nn.Conv2d(1, 100, (4, input_size))\n",
        "        self.fc = nn.Linear(200, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x1 = F.relu(self.conv1(x)).squeeze(3)\n",
        "        x2 = F.relu(self.conv2(x)).squeeze(3)\n",
        "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n",
        "\n",
        "class DPCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DPCNN, self).__init__()\n",
        "        self.conv = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.fc = nn.Linear(100, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x = F.relu(self.conv(x)).squeeze(3)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n",
        "\n",
        "class DomainGate(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(DomainGate, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 9),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, g):\n",
        "        alpha = self.mlp(g)\n",
        "        return alpha\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_size, 384),  # 1152 input units, 384 hidden units\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(384, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, v):\n",
        "        y_hat = self.mlp(v)\n",
        "        return y_hat\n",
        "\n",
        "class SLFENDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SLFENDModel, self).__init__()\n",
        "        self.bert = BertEmbedding('bert-base-uncased')\n",
        "        self.membership_function = MembershipFunction(input_size=768, hidden_size=256)\n",
        "        self.experts = nn.ModuleList([\n",
        "            TextCNN(768, 128),\n",
        "            DCNN(768, 128),\n",
        "            DPCNN(768, 128)\n",
        "        ] * 3)  # 9 experts\n",
        "        self.domain_gate = DomainGate(9)\n",
        "        self.classifier = Classifier(128 )  # Corrected to match 128 features * 9 experts\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids, attention_mask)\n",
        "        # print(f'bert_output: {bert_output.shape}')\n",
        "        soft_labels = self.membership_function(bert_output)\n",
        "        # print(f'soft_labels: {soft_labels.shape}')\n",
        "\n",
        "        # Compute expert outputs\n",
        "        expert_outputs = [expert(bert_output) for expert in self.experts]\n",
        "        expert_outputs = torch.stack(expert_outputs, dim=1)  # Stack to create a tensor of shape [batch_size, num_experts, features]\n",
        "        # print(f'expert_outputs: {expert_outputs.shape}')\n",
        "\n",
        "        alpha = self.domain_gate(soft_labels)  # Alpha of shape [batch_size, num_experts]\n",
        "        # print(f'alpha: {alpha.shape}')\n",
        "\n",
        "        # Ensure alpha has the same shape as expert_outputs for the purpose of element-wise multiplication\n",
        "        alpha = alpha.unsqueeze(-1)  # Shape becomes [batch_size, num_experts, 1]\n",
        "        # print(f'alpha.unsqueeze(-1): {alpha.shape}')\n",
        "\n",
        "        v = (expert_outputs * alpha).sum(dim=1)  # Element-wise multiplication and then sum across experts\n",
        "        # print(f'v: {v.shape}')\n",
        "\n",
        "        # Concatenate expert outputs\n",
        "        v = v.view(v.size(0), -1)  # Flatten to shape [batch_size, 1152]\n",
        "        # print(f'v after view: {v.shape}')\n",
        "\n",
        "        y_hat = self.classifier(v)\n",
        "        # print(f'y_hat: {y_hat.shape}')\n",
        "        return y_hat\n",
        "\n",
        "# Load and preprocess data\n",
        "file_path = '/content/Fake_Real_Data.csv'\n",
        "df = load_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.shape)\n",
        "\n",
        "text_column = 'Text'\n",
        "label_column = 'label'\n",
        "texts, labels = preprocess_data(df, text_column, label_column)\n",
        "\n",
        "# print(f'Number of texts: {len(texts)}')\n",
        "# print(f'Number of labels: {len(labels)}')\n",
        "\n",
        "# Create DataLoader\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_len = 170\n",
        "\n",
        "train_texts, train_labels = texts[:int(0.8*len(texts))], labels[:int(0.8*len(labels))]\n",
        "val_texts, val_labels = texts[int(0.8*len(texts)):int(0.9*len(texts))], labels[int(0.8*len(labels)):int(0.9*len(labels))]\n",
        "test_texts, test_labels = texts[int(0.9*len(texts)):], labels[int(0.9*len(labels)):]\n",
        "\n",
        "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_len)\n",
        "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_len)\n",
        "test_dataset = NewsDataset(test_texts, test_labels, tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Instantiate model and device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SLFENDModel().to(device)\n",
        "\n",
        "# Function to validate DataLoader and model input shapes\n",
        "def validate_dataloader_and_model(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            print(f'input_ids: {input_ids.shape}')\n",
        "            print(f'attention_mask: {attention_mask.shape}')\n",
        "            print(f'labels: {labels.shape}')\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            print(f'outputs: {outputs.shape}')\n",
        "            break  # Only validate the first batch\n",
        "\n",
        "# Validate the DataLoader and model input shapes\n",
        "validate_dataloader_and_model(model, train_loader)\n"
      ],
      "metadata": {
        "id": "R6elaA_MyYyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242aa34f-458b-4c0c-cbea-c96407658b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text label\n",
            "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
            "1  U.S. conservative leader optimistic of common ...  Real\n",
            "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
            "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
            "4  Democrats say Trump agrees to work on immigrat...  Real\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9900 entries, 0 to 9899\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    9900 non-null   object\n",
            " 1   label   9900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 154.8+ KB\n",
            "None\n",
            "(9900, 2)\n",
            "input_ids: torch.Size([16, 170])\n",
            "attention_mask: torch.Size([16, 170])\n",
            "labels: torch.Size([16])\n",
            "outputs: torch.Size([16, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.label_map = label_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        # label = label_map[self.labels[idx]]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_len = 170\n",
        "label_map = {0: 'Real', 1: 'Fake'}\n",
        "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_len)\n",
        "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_len)\n",
        "test_dataset = NewsDataset(test_texts, test_labels, tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "JknYjDnl9mS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, data in enumerate(test_loader):\n",
        "    datas = data['text']\n",
        "    labels = data['label']\n",
        "    print(\"Datas shape:\", len(datas))\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Labels shape:\", len(labels))\n",
        "    print(idx)\n",
        "    print(len(data))\n",
        "    print(data)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWY0AQysY8w",
        "outputId": "c777fea0-7896-480a-9f34-64ffa14122eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datas shape: 16\n",
            "Labels: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
            "Labels shape: 16\n",
            "0\n",
            "4\n",
            "{'text': [' Trump’s TIME Interview Is The Most Batsh*t F*cking Insane Thing You’ll Ever See Donald Trump at this point is known for spewing crazy statements, but in an interview with TIME, The Donald somehow managed to outdo himself in attempting to defend some of his more batsh*t insane lies.Asked about his claim that President Obama put a  tapp  on his  wires  at Trump Tower, The Donald explained that he has  articles saying it happened.  The random, word salady string of words Trump threw together to support this one is so impressively moronic that Sarah Palin seems like a genius by comparison: No, I have, look. I have articles saying it happened. But you have to take a look at what they, they just went out at a news conference. Devin Nunes had a news conference. I mean I don t know, I was unable to see it, because I am at meetings, but they just had a news conference talking about surveillance. Now again, it is in quotes. That means surveillance and various other things. And the New York Times had a front-page story, which they actually reduced, they took it, they took it the word wiretapping out of the title, but its first story in the front page of the paper was wiretapping. And a lot of information has just been learned, and a lot of information may be learned over the next coming period of time. We will see what happens. Look. I predicted a lot of things that took a little of bit of time. Here, headline, for the front page of the New York Times,  Wiretapped data used in inquiry of Trump aides.  That s a headline. Now they then dropped that headline, I never saw this until this morning. They then dropped that headline, and they used another headline without the word wiretap, but they did mean wiretap. Wiretapped data used in inquiry. Then changed after that, they probably didn t like it. And they changed the title. They took the wiretap word out. Devin Nunes did indeed have a  news conference  in which he did attempt to push Trump s lies by pointing out that many of The Donald s associates had been caught up in perfectly legal  incidental collection  while the FBI and other agencies were looking into foreign suspects. Nunes, a prominent member of Trump s transition team, also completely skipped telling his fellow Russia investigators of this development and ran directly to Mr. 45 with the information.Though Nunes has previously said there is no evidence that Obama  tapped  Trump s  wires,  The Donald took the incidental collection of information   a term he admits he does not understand   as proof that he was correct about that dastardly President Obama: Well, he just got this information. This was new information. That was just got. Members, of, let s see, were under surveillance during the Obama Administration following November s election. Wow. This just came out. So, ah, just came out. Trump also told TIME that he will be  proved right  about his wacky claim that three million undocumented immigrants voted for his opponent, swinging the popular vote in Hillary Clinton s favor. Despite the completely false nature of Trump s allegations, he says he s  forming a committee on it  and it may be  more than  three million   a  serious problem. Asked about his completely unfounded claim that thousands of Muslims celebrated in the streets of New Jersey after 9/11, Trump claimed that it was in the Washington Post. This claim has been disputed by literally everyone with any sense.Trump even defended his blatantly incorrect claim that Ted Cruz s father helped kill JFK by saying it was in a  newspaper.  It wasn t, but that didn t stop him from lying again: Well that was in a newspaper. No, no, I like Ted Cruz, he s a friend of mine. But that was in the newspaper. I wasn t, I didn t say that. I was referring to a newspaper. A Ted Cruz article referred to a newspaper story with, had a picture of Ted Cruz, his father, and Lee Harvey Oswald, having breakfast. In fact, according to The Donald, he is not responsible for any of his lies because someone else made the numerous false claims elsewhere and he simply repeated them: Why do you say that I have to apologize? I m just quoting the newspaper, just like I quoted the judge the other day, Judge Napolitano, I quoted Judge Napolitano, just like I quoted Bret Baier, I mean Bret Baier mentioned the word wiretap. Now he can now deny it, or whatever he is doing, you know. But I watched Bret Baier, and he used that term. I have a lot of respect for Judge Napolitano, and he said that three sources have told him things that would make me right. I don t know where he has gone with it since then. But I m quoting highly respected people from highly respected television networks. This is perhaps the most insane interview conducted with the President of the United States. You can read the whole thing here.Featured image via Getty Images (Chip Somodevilla)', ' Hillary UNLOADS On Trump For Attacking Human Rights, Shows GOP Who SHOULD Have Been POTUS (VIDEO) On Thursday, Hillary Clinton ripped Donald Trump and his bigoted administration apart for being on the wrong side of history and refusing to defend LGBT rights   and while she was at it, she showed conservatives just what they missed out on by letting a former reality television star get into the White House instead of a well-qualified politician.At a fundraiser for LGBT community organization The Center, Clinton received an award and gave a speech in which she thanked her audience for their continued support. However, her message came with a chilling warning about the Trump administration as she said the progress that we fought for, that many of you were on the front lines for. It may not be as secure as we once expected.  Clinton blasted Trump: We may not ever be able to count on this administration to lead on LGBT issues. Then, she couldn t resist rattling off several of the things Trump has been doing to directly attack and weaken the LGBT community. She said: When this administration rescinded protections for transgender students, my heart broke. When I learned about the proposed cuts in funding for HIV and AIDS research, I thought about all of our efforts to try and achieve an AIDS-free generation. Some of the changes that we re seeing should seem small, but they matter a great deal if you re the person affected. Others carry historic significance, like the future of the Supreme Court. While Clinton was not always a supporter of same-sex marriage, she had changed her tone several years ago and has been a powerful ally since. In her usual classy way, she called on Americans to stick together and unite to protect human rights and resist homophobia. Clinton said: I know the election hit a lot of us hard. I can tell you this: Even when it feels tempting to pull the covers over your heads, please keep going. Clinton s skilled and powerful delivery is something that Trump could only dream to emulate one day. Despite having lost the election to Trump, the majority of Americans still love and support Clinton, as Trump s approval rating plummets by the day. The support for her message shows that America no longer supports the values of the GOP any longer, and that conservatives have made a major mistake by putting Trump in the White House.You can watch Clinton s speech below: Featured image via Drew Angerer and Mark Wilson / Getty Images', 'Trump does not recall suggestion of Putin meeting: White House WASHINGTON (Reuters) - U.S. President Donald Trump does not recall a meeting with his foreign policy advisers in March 2016 in which one of them suggested he could arrange a meeting between candidate Trump and Russian President Vladimir Putin, the White House said on Wednesday. George Papadopoulos, an obscure Trump campaign adviser, pleaded guilty to lying to FBI agents about contacts with people who claimed to have ties to top Russian officials, in the first criminal charges alleging links between the campaign and Moscow, according to court documents released on Monday. According to the court documents, Papadopoulos, a Chicago-based international energy lawyer, told the March 31, 2016, meeting that he had connections that could help arrange a Trump-Putin meeting. Asked at a news briefing if the Republican president recalled the suggestion by Papadopoulos, White House spokeswoman Sarah Sanders said: “No I don’t believe he does.” The charges against Papadopoulos were made public just after indictments charging Trump’s former campaign manager Paul Manafort and another aide with multiple offenses, including money laundering, conspiracy against the United States and failing to register as foreign agents. The New York Times said Trump, in a telephone conversation with the newspaper on Wednesday, said investigations into possible collusion between his campaign and Russia had not come anywhere near him personally. “I’m not under investigation, as you know,” the Times quoted Trump as saying. Pointing to Manafort’s indictment, the president said:  “There’s not even a mention of Trump in there,” according to the Times. “It has nothing to do with us.” U.S. intelligence agencies said in January that Russia had meddled in the 2016 U.S. presidential campaign to discredit Trump’s Democratic rival, Hillary Clinton. Trump has denounced the investigations as a witch hunt. Russia denies meddling in the U.S. election. Manafort and Rick Gates on Monday pleaded not guilty to the charges, some of which go back more than a decade and center on Manafort’s work for Ukraine. Neither Trump nor his campaign was mentioned in the indictment against Manafort and Gates.  ', 'Trump administration weighs tighter vetting for women, children refugees: sources WASHINGTON/NEW YORK (Reuters) - The Trump administration is considering tightening the vetting process for women and children seeking to enter the United States as refugees, a proposal that if adopted would bring security checks closer to those for adult men, three sources with knowledge of the plan told Reuters. The plan could slow down refugee admissions even after the end of a 120-day ban on most refugees instituted by the Trump administration while it reviews vetting procedures. The vetting review is set to end on Oct. 24. President Donald Trump came into office in January with a goal of sharply cutting refugee admissions, in line with the hard-line immigration policies that were a focal point of the Republican’s 2016 election campaign. Trump quickly issued temporary bans on refugees and travelers from some Middle Eastern and African countries that were challenged in court. A U.S. official told reporters last month that the administration is “considering a wide range of potential measures and enhancements” to vetting. Refugees currently undergo differing levels of security checks when applying for admission to the United States, depending on the perceived risk they might present, including running their biographic and biometric data against law enforcement and intelligence databases. Women and young children go through a lower level of security screening than men, said the three sources with knowledge of the proposal, who spoke on condition of anonymity. The proposed changes would bring their security checks more in line with what is required for adult male refugees. Successive Republican and Democratic administrations have focused most of their attention on adult men who tend to join militant groups such as al Qaeda and Islamic State in greater numbers than women. A State Department official declined to comment on any refugee vetting processes while the review is underway. The government is taking steps to “further intensify” refugee screening “to uphold the safety of the American people,” the official said. Department of Homeland Security spokesman Dave Lapan declined to comment, and said the administration is “finalizing security enhancement recommendations as part of the 120-day review.” A White House spokeswoman said there were “no announcements at this time.” All refugees referred for resettlement in the United States are run through a database with watch-list information, called the Consular Lookout and Support System, or CLASS. Refugees can be singled out for a higher level of review based on their age, nationality, or gender. Syrian refugees, for instance, undergo extra checks. Of the nearly 85,000 refugees admitted to the United States in the 2016 fiscal year, about 72 percent were women or children, according to the State Department. Total processing time for refugees to enter the United States now averages about 18 to 24 months, according to the State Department.  Trump’s order to halt refugee admissions so his administration could determine whether additional checks are necessary was suspended for months by federal judges. The U.S. Supreme Court eventually allowed it to go in effect for all refugees except those with close ties to the United States.  Trump also lowered the maximum number of refugees to be allowed into the United States in 2017 to 50,000 from the 110,000 originally set by former President Barack Obama, a Democrat. The 2018 level has been set at 45,000, the lowest number in decades. ', ' Trump Goes Mental On Threats To North Korea, This Is His Most Dangerous One Yet (VIDEO) Donald Trump has now taken his threats to North Korea off Twitter and is making them to the public. Quite frankly, the situation is getting more terrifying as the days go on.After tweeting this morning that U.S. military solutions were  locked and loaded,  Trump made some very disturbing comments when speaking to reporters this afternoon at his New Jersey golf course, where he is enjoying a 17-day vacation.When a reporter asked Trump about his ominous tweet, Trump stated that he meant exactly what he said and that his words are very, very easy to understand.  Trump also said that the Trump administration would be  very, very successful  in acting swiftly on North Korea, right before directly attacking North Korean leader Kim Jong-un. Trump said: And if he utters one threat in the form of an overt threat, which, by the way, he has been uttering for years, and his family has been uttering for years, or if he does anything with respect to Guam or any place else that s an American territory or an American ally, he will truly regret it, and he will regret it fast. This all began when Trump threatened North Korea with  fire and fury  on Tuesday, and now we re here. Trump is leading America down a dangerous road, and he barely understands the consequences that will follow. He carelessly speaks through his insecurities and fragile ego and shows no concern for how irresponsible his comments actually are. Trump is more concerned with looking like a tough leader (and like a dictator) than he is with improving the country and keeping peaceful working relations with the rest of the world. If this is the kind of disaster we are looking at just a few months into Trump s presidency, the world will be in shambles if he lasts four years.You can watch this disturbing Trump footage below:Featured image via Drew Angerer /Getty Images', ' Desperate Lindsey Graham Calls Clinton Foundation Controversy A “Gift From The Political Gods” (VIDEO) Senator Lindsey Graham has had an on-again, off-again relationship with Donald Trump, having first condemned and opposed the Republican nominee, then endorsed, un-endorsed, tried to get his other GOP buddies to also stop supporting him, and now he seems to be back on the Trump bandwagon in hopes that by getting The Donald elected, Republicans can keep the Senate.That s why Graham is particularly thrilled about a recent report on the Clinton Foundation that outlines that  more than half of the private individuals who met with Hillary Clinton during her tenure as Secretary of State were also donors to the Clinton Foundation in some capacity  and that Clinton had given those donors favorable treatment.In an interview with Fox News on Wednesday, Graham celebrated this  gift from the political gods , claiming that this might actually help Trump  close the gap  with the Democratic nominee   but only if Trump plays his cards right (and we all know what the slim chances of that happening are). Graham said: If Mr. Trump can up his game   and he is, he s doing much better. If he can control   if he can close the gap I think the chance of keeping the Senate goes up. Graham also criticized the Clinton report, saying that it reeks of wrong, it reeks of insider benefits, the inside versus the outside, and Trump represents the outside and he s in a pretty good spot.  Obviously, Graham isn t considering that Trump s own business and charity record is filled with unethical, fraudulent activity.This interview gets somewhat comical when Graham said, with a straight face, that if only Trump could harness his  temperament , demonstrate  judgment  and show that he was  qualified  to be the next President of the United States, he might be able to make the Republican Party proud. Unfortunately, we all know that Trump is just going to disappoint Graham and break his heart   again.You can watch the interview below:Featured image via Darren McCollester / Getty Images', ' Lindsey Graham Sends A Final ‘F*** You’ To Trump As He Announces Who He Voted For (TWEETS) This election has been hard for South Carolina senator Lindsey Graham. After fighting his little Republican heart out in the primaries only to see a reality TV star defeat him and every other more qualified GOPer, Graham continued to be devastated long after Trump became the Republican nominee.Graham s journey through Trump s campaign has been nothing short of an emotional roller coaster, starting with him trashing The Donald and refusing to keep his promise to support the party s nominee regardless of who it was. Then, Graham eventually decided to support Trump after much hesitance, only to completely disown him in the end after one too many offensive statements and erratic stunts. Needless to say, Graham is probably one of the most relieved people in the GOP that this election has finally come to an end.On Tuesday, Graham decided to celebrate Election Day with one more final  F*ck You  to Trump, someone that Graham clearly doesn t think deserves to be anywhere near the White House. Using his hatred for Trump as the inspiration behind his voting choice, Graham announced who he actually voted for on Twitter, and it s going to break Trump s little black heart:TwitterTwitterTwitterGraham decided that since he can t stand the thought of voting for Trump but didn t want to vote for Hillary Clinton, either, that he would just vote for the next best thing in his mind   Evan McMullin, who came into the election late with the simple goal of being an alternative to Trump.Graham is the very first senator to publicly say that he s voting for the conservative independent candidate, and it s a huge slap in the face to Trump. We expect that many more disgruntled Republicans will be making similar choices, although many may not have the courage to actually admit it.Featured image via Chip Somodevilla and Alex Wong / Getty Images', ' Donald Trump Will Throw A Hissy Fit After Reading George Will’s Review Of His Inaugural Address Donald Trump thinks his inaugural address was the best ever. George Will emphatically disagrees.As it became clear that Trump would be the Republican nominee last year, the longtime conservative columnist left the Republican Party in disgust.Trump, of course, lashed out by calling Will  overrated.  But Will fired back by nailing Trump s lack of intelligence.And after Will s review of Trump s speech, it looks like it s only a matter of time before Trump lashes out again.Trump delivered his inaugural address on Friday as a pathetic crowd watched and cheered after every word he uttered.Trump lied repeatedly and made promises he won t keep while portraying America as an apocalyptic wasteland where poverty and crime reign and the military is crippled. It was a divisive and negative speech that ignores all the progress America made over the last eight years after a devastating recession nearly flattened our economy.But Trump thinks his speech was great and Fox News stroked his fragile ego by agreeing with him.George Will, however, was not impressed. Twenty minutes into his presidency, Donald Trump, who is always claiming to have made, or to be about to make, astonishing history, had done so,  Will began in his column for the Washington Post.  Living down to expectations, he had delivered the most dreadful inaugural address in history. Will took on Kellyanne Conway s promise that Trump s speech would be  elegant. This is not the adjective that came to mind as he described  American carnage,  Will wrote.  That was a phrase the likes of which has never hitherto been spoken at an inauguration. Oblivious to the moment and the setting, the always remarkable Trump proved that something dystopian can be strangely exhilarating: In what should have been a civic liturgy serving national unity and confidence, he vindicated his severest critics by serving up reheated campaign rhetoric about  rusted out factories scattered like tombstones across the landscape  and an education system producing students  deprived of all knowledge.  Yes, all. But cheer up,  Will continued.  Because the carnage will vanish if we  follow two simple rules: Buy American and hire American.   Simple  is the right word. Indeed, Trump literally said this and tweeted it on Friday even though he doesn t obey those two rules himself.Will went on to reference Ronald Reagan s first inauguration and responded directly to Trump s declaration that  What truly matters is not which party controls our government but whether our government is controlled by the people  by cleverly quoting words James Madison would use today to comment on Trump s rise to the presidency. A dependence on the people,  James Madison wrote,  is, no doubt, the primary control on the government; but experience has taught mankind the necessity of auxiliary precautions.  He meant the checks and balances of our constitutional architecture. They are necessary because, as Madison anticipated and as the nation was reminded on Friday,  Enlightened statesmen will not always be at the helm. Mic. Dropped. And now we wait for Donald Trump s temper tantrum.Featured image via screenshot', ' Trump’s ‘Illegal Votes’ Lie Just Turned The Whole Recount Issue Into One Long Alex Jones Episode By now, we ve all seen the tweet where Trump said that he won the popular vote in a landslide if  millions of illegal votes  are taken out of the count. We also all know that Trump wouldn t be saying a damn thing if he were confident that possible recounts didn t have a hope in hell of overturning the election results. Regardless, where in the name of all that s profane is he getting this idea that millions of illegal votes were cast?Trump is a conspiracy theorist. He believes people like Alex Jones. And Alex Jones is probably the most prominent person to  report  on these supposedly illegal votes right now. According to Politifact, about six days after the election, InfoWars published a story with a headline that reading:  Report: 3 Million Votes in Presidential Election Cast by Illegal Aliens. That s a rather serious claim to make. This is Alex Jones, though, so wondering if he has legitimate supporting evidence for that claim is pointless. He actually got his number from a pair of tweets from Gregg Phillips, the founder of VoteStand. VoteStand is a voter-fraud detection app, and he says he s gone through 180 million voter registrations and found 3 million  non-citizens  on the rolls:Completed analysis of database of 180 million voter registrations.Number of non-citizen votes exceeds 3 million.Consulting legal team.  Gregg Phillips (@JumpVote) November 11, 2016We have verified more than three million votes cast by non-citizens.We are joining .@TrueTheVote to initiate legal action. #unrigged  Gregg Phillips (@JumpVote) November 13, 2016Sprinkled throughout Phillips  Twitter feed are more tweets claiming he s got the evidence, but he won t release it to Politifact or anybody else. Yet, just the existence of tweets from an app founder who s paranoid as all fuck about voter fraud is enough for Jones, which is enough for Trump. So Trump will loudly proclaim he won the popular vote, because obviously.And there you have it. We have a president who s likely to turn the next four years into a giant InfoWars episode. It s enough to make us want to put our fists through a window.Featured image via Drew Angerer/Getty Images', ' New Poll Has Very Bad News For The NRA (DETAILS) While it may not come as much of a surprise that the leadership at the National Rifle Association (NRA) has a different opinion on gun control than the average American, what is surprising is that same leadership holds a different opinion than the American gun owner. According to a new poll, at least 67 percent of gun owners in the United States believe that the organization has changed its mission from one promoting gun safety to one dominated by professional lobbyists. They say the NRA has been  overtaken by lobbyists and the interests of gun manufacturers and lost its original purpose and mission. The NRA of today looks very different from what it looked like before. In fact, for most of its history, it supported, and even wrote, gun control legislation. Adam Winkler, author of Gunfight: the Battle Over the Right to Bear Arms in America, wrote,  Historically, the leadership of the NRA was more open-minded about gun control than someone familiar with the modern NRA might imagine. To understand the relationship the NRA has with gun control. It may help to look at who and why it was founded. After the Civil War, many people in the North believed that people in the South possessed superior skills in the area of using rifles. They blamed that for the length of the war. The national slogan for the NRA was,  Firearms Safety Education, Marksmanship Training, Shooting for Recreation.  Its main goal was to improve men s marksmanship, not ward off threats to the Second Amendment. The organization was founded in 1871.That effort didn t start until the 1970s. In 1934, the nation saw its first piece of gun control legislation signed into law. The National Firearms Act of 1934 was designed to  make it difficult for any not law abiding citizen to obtain a pistol or revolver.  It was authored, in part, by the NRA. They also helped write the Gun Control Act of 1938.When these bills were written and signed into law, Karl T. Frederick was president of the NRA. He said,  I have never believed in the general practice of carrying weapons. I do not believe in the general promiscuous toting of guns. I think it should be sharply restricted and only under licenses. For about a century, the NRA s motto remained the same. Then the 1960s happened. With the unrest of the assassinations and the rise of the Black Panthers, The Mulford Act was passed in California. It barred people from carrying loaded weapons around outside. While it was supported by the NRA, the backlash that it spurred also galvanized a new wave of gun support. About a decade after the act was signed into law, a group of gun rights supporters took over the NRA. They ousted the leadership and changed the motto to,  The Right Of The People To Keep And Bear Arms Shall Not Be Infringed. Since then, the NRA has opposed many measures that have had widespread support from the American public. In poll after poll, people say they want people who buy guns to pass background checks, they want to limit the capacity of rifles and they support common sense gun control legislation. Even Supreme Court Justice Anontin Scalia supported limiting some of this. In his Heller v. DC decision, Scalia wrote,  Nothing in our opinion should be taken to cast doubt on longstanding prohibitions on the possession of firearms by felons and the mentally ill, or laws forbidding the carrying of firearms in sensitive places such as schools and government buildings, or laws imposing conditions and qualifications on the commercial sale of arms. New data show more support for gun control from gun owners. While the NRA leadership says one thing, the average gun owner thinks another. A few years ago, Wayne LaPierre, NRA chief, said,  The only thing that can stop a bad man with a gun is a good man with a gun.  This is the response from gun owners to that new poll.For its part, the NRA is disputing the accuracy of the poll. Jennifer Baker, spokesperson for the NRA said,  The NRA s strength is derived from our five million members and the tens of millions of Second Amendment supporters who vote. The majority of Americans oppose gun control and they made their voices heard this past November. This was a poll paid for by a gun control group, so it s not surprising that the so called  results  further their agenda. Public Policy Polling conducted the poll between April 19 and 20. It included 661 people who own guns. The margin of error is four percentage points. Americans for Responsible Solutions commissioned the poll.Featured image via Alex Wong/Getty Images', ' Trump Finally Delivers On Promised Phone Call To Soldier’s Wife, Says The Most Disgusting Thing EVER After two days of controversy over Donald Trump s lack of response, attention, or even seeming to notice the four soldiers who died in an ambush in Niger nearly two weeks ago, he finally called the pregnant widow of one of the fallen soldiers, Sergeant LaDavid Johnson. At Miami International Airport, where she awaited the remains of her 25-year-old husband, Myeshia Johnson took the president s 5-minute call.On hand with Myeshia Johnson was Congresswoman Frederica Wilson, the US Representative from Johnson s district. Wilson has been critical of Trump s response   or lack of one   for longer than this has even been in the national spotlight. Sgt. Johnson s body was left behind after the ambush, and not recovered by the military for two days after the operation. Many questions remain about the ambush, the operation, and the planning that went into the entire effort. Some consider Trump s bluster on calling military families and his attack on President Barack Obama to be a distraction from those questions that have arisen.According to Rep Wilson, the phone call was  insensitive and insane,  and if accurate, what she conveyed from Sgt. Johnson s widow is possibly the worst thing anyone has ever said to the widow of a soldier, let alone the worst thing a president has said. Trump told Mrs. Johnson, He knew what he signed up for But when it happens it hurts anyway. Those are the words of a man who has either never suffered a loss or has never cared about one.The call was first reported by Ross Palombo, the Washington Bureau Chief for an ABC affiliate in Miami. After Palombo tweeted about the Congresswoman s account of the call, he was contacted by the White House, only for officials to chide him and tell him that the affair was none of his business:BREAKNG: Top White House official tells me about @realDonaldTrump comment to soldier s widow  The President s conversations with the families of American heroes who have made the ultimate sacrifice are private.  @WPLGLocal10  Ross Palombo (@RossPalombo) October 18, 2017This kind of response is, unfortunately, just what America has come to expect from the disgusting Donald Trump and his cohorts in the White House.Featured image via Mark Wilson/Getty Images', ' Democrat Forces Trump’s Own Nominee To MOCK Him, Admit Obama’s Inauguration Was Bigger (VIDEO) Donald Trump is fuming over the size of his little inauguration last weekend. Not only did his inauguration have embarrassingly low attendance numbers when compared to Barack Obama s previous inaugurations, but it was also completely outnumbered by the Women s March, which was a protest AGAINST him!Trump has tried to make his inauguration look less pathetic by having his team spew lies, despite the fact that photographic evidence clearly shows that almost no one went to see him get sworn in as the 45th President of the United States. While Trump continues to soothe his monstrous ego on Twitter, his political opponents are having the time of their lives mocking him   and what Democratic Senator Jeff Merkley just did was the perfect way to troll someone like Trump.At the confirmation hearing for Rep. Mike Mulvaney (R-SC), Trump s pick for director of the Office of Management and Budget, Merkley forced Mulvaney to humiliate Trump in front of everyone by showing side by side photos of Trump s inauguration and Obama s 2009 inauguration. To make things even worse, Merkley asked Mulvaney to publicly state which inauguration crowd was bigger.Faced with the evidence and a room full of peers, Mulvaney was forced to admit what Trump and his team wouldn t: that Obama s inauguration crowd was bigger. Merkley then tied it all together, making sure to state his point in mocking Trump. He said: The reason I m raising this is because budgets often contain varied deceptions. You and I talked in my office about the  magic asterisk.  This is an example of something where the president s team, on something very simple and straightforward, wants to embrace a fantasy rather than a reality. You can watch this beautiful moment below:Later, Merkley made sure Mulvaney got the point by calling on him to give actual budgets instead of the  alternative facts  Trump s team has become well known for.This was absolutely brilliant, and we need more senators calling Trump and his team out for their lies. They need to be held accountable, and this was a great way to do it.Featured image via Chip Somodevilla / Getty Images', 'Tillerson to press China and ASEAN states on North Korea in Manila WASHINGTON (Reuters) - U.S. Secretary of State Rex Tillerson will press China and other Asian countries to take tougher action against North Korea when he attends regional meetings in Manila starting this week, a senior U.S. official said on Wednesday. Susan Thornton, the acting assistant secretary of state for East Asia, said Tillerson would have the chance to engage with China’s foreign minister at the meetings of the Association of Southeast Asian Nations in Manila, but had no plans to meet North Korea’s foreign minister there. Thornton said Tillerson, who is due in Manila on Saturday, would be seeking greater cooperation in isolating North Korea and in enforcing U.N. sanctions over its missile and nuclear weapons programs. She said Washington wanted to see countries “drastically” reduce their dealings with Pyongyang. “What we are trying to do is galvanize this pressure and isolate North Korea so it can see what the opportunity cost is over developing these weapons programs,” she told reporters in a telephone briefing to preview Tillerson’s trip. Thornton said China had taken “significant steps, ... frankly unprecedented steps” to increase pressure on its neighbor North Korea, but it could do “a lot more” to step up enforcement of existing sanctions and to impose more. “We would like to see more action faster and more obvious and quick results, but I think we’re not giving up yet.” Thornton’s remarks contrasted with those of U.S. President Donald Trump, who on Saturday accused Beijing of doing “nothing” to help on North Korea and pointed to the huge U.S. trade deficit with China. A senior Trump administration official said on Tuesday that Trump was close to a decision on how to respond to what he considers China’s unfair trade practices and was considering action that could lead to tariffs or other trade restrictions on Chinese goods. Thornton declined to comment on any possible action but stressed that despite Trump’s tweets, North Korea and the trade issue were not linked in a “transactional,” but “in a sort of philosophical way.” “Can we work together jointly on the key security challenge facing Northeast Asia, which is the North Korea challenge?” she said. “If we can work together to do that, surely we can have a productive, mutually beneficial economic relationship in which we both enjoy reciprocal and fair access to each other’s markets.” Thornton said Tillerson would continue to press China on the South China Sea issue while in Asia, where the United State has been pressing for rapid adoption of a code of conduct over competing territorial claims. She said the United States would “certainly” raise human  rights with Philippine President Duterte’s government. U.S. criticism of Duterte’s bloody war on drugs under Trump’s predecessor Barack Obama damaged relations between the long-standing allies. Duterte has remained defiant, accusing critics of “trivializing” his drug campaign with human rights concerns. Tillerson will also visit Thailand next Tuesday and then Malaysia. His visit to Bangkok will be the first by a U.S. secretary of state since before the military seized power in a 2014 coup. ', ' Donald Trump Just Announced Another Position For Ivanka And Americans Are Outraged Donald Trump has just announced that his daughter Ivanka (you know, the one he wants to date) will be taking on yet another role within his disastrous excuse for an administration. Via Twitter, Trump proclaimed that his oldest daughter  will lead the U.S. delegation to India this fall. .@IvankaTrump will lead the U.S. delegation to India this fall, supporting women s entrepreneurship globally.#GES2017 @narendramodi  Donald J. Trump (@realDonaldTrump) August 10, 2017Go figure, Americans are not the least bit impressed that a handbag designer with zero qualifications who was neither elected nor appointed will be serving in this role. Twitter users wasted no time telling Trump all about it.Yeah, just send your Daughter, who has no experience in such to do this. I mean what could possibly go wrong, right?  Impeach Donald Trump (@Impeach_D_Trump) August 10, 2017Here you go again, once more giving your job to someone who has no clue what she\\'s doing! Why can\\'t you be presidential?  Jail Donald Trump (@DTrumpExposed) August 10, 2017I\\'m glad you feel your family are more qualified than millions of actual diplomats, but there\\'s this crazy thing called nepotism. pic.twitter.com/gjGUVSZZ1l  Alt Fed Employee (@Alt_FedEmployee) August 10, 2017Ivanka Trump makes nepotism great again. This is an affront to our democracy.  Eugene Gu, MD (@eugenegu) August 10, 2017It was bad enough when Ivanka said she was working \\'alongside\\' General Kelly. Trump should fill positions w/ qualified people, not relatives  Dani Bostick (@danibostick) August 10, 2017Isn\\'t she just going out there to scout more sweatshop sites?  Joel Gleicher (@JoelG_88) August 10, 2017She\\'s more likely to visit the factories where they\\'re being made while there.  Muse (@ATLmuse) August 10, 2017Look at this Nepotism. pic.twitter.com/P7heuRujai  Gerren Peterson (@GerrenPeterson) August 10, 2017wtf man she\\'s a handbag designer not a diplomat  Daeso (@DTLAWOLF) August 10, 2017Maybe someone who isn\\'t too busy trying to keep her lunatic father from starting WWIII to try and garner more support?  Alt Fed Employee (@Alt_FedEmployee) August 10, 2017What happened to her \"staying out of politics\"?#Complicit#BadMother#Liar#Russia#NotMadeInAmerica#Hypocrisy #Nepotism  JoeMed ?? ? (@joemed3) August 10, 2017Featured image via Mark Wilson/Getty Images', ' Trump Just Got DESTROYED By J.K. Rowling For His Attack On The Free Press – Here’s How (TWEET) Donald Trump topped off his disastrous press conference on Thursday by calling the press  the enemy of the American people  on Friday, and is thankfully getting all the criticism and backlash he deserves.One of Trump s harshest and most outspoken critics, author J.K. Rowling, slammed Trump s comments about the press without even using any of her own words. Brilliantly quoting former President Theodore Roosevelt, Rowling tweeted to educate Trump on just how the free press worked, in case dictator Trump and the GOP forgot. In the tweet, Rowling pointed out that Roosevelt had written: To announce that there must be no criticism of the President, or that we are to stand by the President right or wrong is morally treasonable to the American public. Rowling even used the trending #NotTheEnemy hashtag to show her support for the press. Check out the full tweet below:Exactly. The free press is protected by the U.S. Constitution, a document that Trump desperately needs to read before he does or says something else that will make him look foolish. In his attacks on the media, it s clear that Trump wants  unquestioned,  unchecked and unlimited power   and doesn t care if it interferes with the very values that this country was built on. Trump wants to operate as if his word is law and that his alternative facts are the only truth Americans should be digesting without a second thought.Trump seems to be oblivious to the real responsibilities of the job he signed up for, as well as the fact the he actually works for the American people   not the other way around. What Rowling did perfectly put Trump in his place and reminded the undeserving POTUS just exactly how a democracy is supposed to work.Featured image via Ben A. Pruchnie and Mario Tama / Getty Images', 'Bipartisan Illinois House group urges Senate to pass budget fix CHICAGO (Reuters) - A bipartisan group of 30 Illinois House members on Tuesday threw their support behind efforts in the Senate to craft a bill package aimed at ending the state’s historic budget impasse. “We ask the senators from both parties to pass the best negotiated package they can, and then we will take up their work in the House,” the group said in a statement.  The package, which includes tax hikes, pension changes and a local property tax freeze, stalled in the Democratic-led Senate in March, when most Republicans withdrew their support. John Patterson, a spokesman for Senate President John Cullerton, said on Tuesday both sides are “trading ideas in trying to find agreement.” Illinois is limping toward the June 30 end of a second-straight fiscal year without a complete budget due to a standoff between its Republican governor and Democrats who control the legislature. Lawmakers face a May 31 deadline to pass budget bills with simple majority votes. The bipartisan House statement surfaced after House Speaker Michael Madigan on Monday urged Governor Bruce Rauner to restart budget negotiations and appointed four top Democrats from his chamber to work on a deal. Meanwhile, the Chicago-based Civic Federation, a nonpartisan government finance watchdog, released a report on Tuesday calling for an end to piecemeal funding that has kept the nation’s fifth-largest state operating. “The governor and General Assembly need to end this unacceptable stalemate by passing and enacting a comprehensive plan,” Civic Federation President Laurence Msall said in a statement. “Cherry-picking certain areas of government to fund while pledging to work toward a complete budget sometime in the abstract future has not and will not end the crisis and in fact is making it worse.” Illinois’ reliance on continuing appropriations, court-ordered spending and partial budgets has ballooned an unpaid bill backlog from $9.1 billion at the end of fiscal 2016 to more than $13 billion in fiscal 2017. Illinois Comptroller Susana Mendoza told a Senate committee on Tuesday that late payment penalties owed to vendors total about $800 million. Eleni Demertzis, a Rauner spokeswoman, said the governor continues to push for “a truly balanced budget with structural reforms.”  Major rating agencies, which have pushed Illinois down the credit scale six times since Rauner took office in January 2015, have indicated the state’s triple-B bond ratings could fall closer to junk in the absence of a fiscal fix. '], 'input_ids': tensor([[  101,  8398,  1521,  ...,  2018,  1037,   102],\n",
            "        [  101, 18520,  4895,  ...,  2089,  2025,   102],\n",
            "        [  101,  8398,  2515,  ...,  1996, 10293,   102],\n",
            "        ...,\n",
            "        [  101,  6221,  8398,  ...,  1010,  2074,   102],\n",
            "        [  101,  8398,  2074,  ...,  1996,  2343,   102],\n",
            "        [  101, 12170, 26053,  ...,  3442, 10807,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), 'label': tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEmbedding(nn.Module):\n",
        "    def __init__(self, bert_model_name):\n",
        "        super(BertEmbedding, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n"
      ],
      "metadata": {
        "id": "Ynw0L86r-Ugv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeapGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LeapGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRUCell(input_size, hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2 + input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            ht = self.gru(x[:, t, :], h)\n",
        "            context = torch.cat([h, ht, x[:, t, :]], dim=-1)  # Concatenate h, ht, and x[:, t, :]\n",
        "            pi = self.mlp(context)\n",
        "            skip_prob = pi[:, 1]\n",
        "\n",
        "            if skip_prob.mean() >= 0.5:\n",
        "                h = ht\n",
        "            outputs.append(h)\n",
        "\n",
        "        outputs = torch.stack(outputs, dim=1)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "S8jjd49D-6xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MembershipFunction(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MembershipFunction, self).__init__()\n",
        "        self.leap_gru = LeapGRU(input_size, hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 9),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        leap_gru_output = self.leap_gru(x)\n",
        "        h = leap_gru_output[:, -1, :]  # Use the last hidden state\n",
        "        g = self.mlp(h)\n",
        "        return g\n"
      ],
      "metadata": {
        "id": "zsGOg3Vb-8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.conv2 = nn.Conv2d(1, 100, (4, input_size))\n",
        "        self.conv3 = nn.Conv2d(1, 100, (5, input_size))\n",
        "        self.fc = nn.Linear(300, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x1 = F.relu(self.conv1(x)).squeeze(3)\n",
        "        x2 = F.relu(self.conv2(x)).squeeze(3)\n",
        "        x3 = F.relu(self.conv3(x)).squeeze(3)\n",
        "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "        x = torch.cat([x1, x2, x3], dim=1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n",
        "\n",
        "class DCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.conv2 = nn.Conv2d(1, 100, (4, input_size))\n",
        "        self.fc = nn.Linear(200, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x1 = F.relu(self.conv1(x)).squeeze(3)\n",
        "        x2 = F.relu(self.conv2(x)).squeeze(3)\n",
        "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n",
        "\n",
        "class DPCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DPCNN, self).__init__()\n",
        "        self.conv = nn.Conv2d(1, 100, (3, input_size))\n",
        "        self.fc = nn.Linear(100, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x = F.relu(self.conv(x)).squeeze(3)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "W7E0wPWP--Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DomainGate(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(DomainGate, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128 * 9, 9),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, g):\n",
        "        alpha = self.mlp(g)\n",
        "        return alpha\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_size * 3, 384),  # Change to 384 hidden units\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(384, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, v):\n",
        "        v = v.view(v.size(0), -1)  # Flatten v to have shape [batch_size, input_size * 3]\n",
        "        y_hat = self.mlp(v)\n",
        "        return y_hat\n"
      ],
      "metadata": {
        "id": "wvhCzpuW-_RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLFENDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SLFENDModel, self).__init__()\n",
        "        self.bert = BertEmbedding('bert-base-uncased')\n",
        "        self.membership_function = MembershipFunction(input_size=768, hidden_size=256)\n",
        "        self.experts = nn.ModuleList([\n",
        "            TextCNN(768, 128),\n",
        "            DCNN(768, 128),\n",
        "            DPCNN(768, 128)\n",
        "        ] * 3)  # 9 experts\n",
        "        self.domain_gate = DomainGate(128 * 9)\n",
        "        self.classifier = Classifier(128 * 9)  # 128 features * 9 experts\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids, attention_mask)\n",
        "        soft_labels = self.membership_function(bert_output)\n",
        "\n",
        "        # Compute expert outputs\n",
        "        expert_outputs = [expert(bert_output) for expert in self.experts]\n",
        "        expert_outputs = torch.stack(expert_outputs, dim=1)  # Stack to create a tensor of shape [batch_size, num_experts, features]\n",
        "\n",
        "        alpha = self.domain_gate(soft_labels)  # Alpha of shape [batch_size, num_experts]\n",
        "\n",
        "        # Ensure alpha has the same shape as expert_outputs for the purpose of element-wise multiplication\n",
        "        v = (expert_outputs * alpha.unsqueeze(-1)).sum(dim=1)  # Element-wise multiplication and then sum across experts\n",
        "        # v = v.view(v.size(0), -1)\n",
        "        # y_hat = self.classifier(v)  # Element-wise multiplication and then sum across experts\n",
        "        v = v.view(v.size(0), -1)\n",
        "        y_hat = self.classifier(v)\n",
        "        return y_hat\n"
      ],
      "metadata": {
        "id": "-hrhhpL5_Adw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=2e-5):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    best_f1 = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        val_loss, val_f1 = evaluate_model(model, val_loader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss}, Val F1: {val_f1}')\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = outputs.cpu().numpy() > 0.5\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    val_f1 = f1_score(all_labels, all_preds)\n",
        "    return val_loss / len(val_loader), val_f1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SLFENDModel().to(device)\n",
        "train_model(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfDR8EI799rx",
        "outputId": "a4d9460f-97f6-4e43-ecd2-dff6735070ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.08339883016817498, Val Loss: 0.00203139852214184, Val F1: 1.0\n",
            "Epoch 2/10, Train Loss: 0.0032179812541480806, Val Loss: 0.0003052214026777825, Val F1: 1.0\n",
            "Epoch 3/10, Train Loss: 0.007373683090495755, Val Loss: 0.00037487385411476417, Val F1: 1.0\n",
            "Epoch 4/10, Train Loss: 0.0017202785390610289, Val Loss: 0.00028191484682705073, Val F1: 1.0\n",
            "Epoch 5/10, Train Loss: 0.00020100016898306255, Val Loss: 7.663056086101043e-05, Val F1: 1.0\n",
            "Epoch 6/10, Train Loss: 6.642031290870032e-05, Val Loss: 3.8347238225997574e-05, Val F1: 1.0\n",
            "Epoch 7/10, Train Loss: 3.795416449782241e-05, Val Loss: 2.2427356740198804e-05, Val F1: 1.0\n",
            "Epoch 8/10, Train Loss: 2.3485710480232192e-05, Val Loss: 1.427956962171236e-05, Val F1: 1.0\n",
            "Epoch 9/10, Train Loss: 1.5581323774000854e-05, Val Loss: 9.54752990324895e-06, Val F1: 1.0\n",
            "Epoch 10/10, Train Loss: 1.0902190212683042e-05, Val Loss: 6.633020692818043e-06, Val F1: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc\n",
        "criterion = nn.BCELoss()\n",
        "def train_model(model, train_loader, val_loader, test_loader, num_epochs=10, learning_rate=2e-5,,  ):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    best_f1 = 0\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    train_aucs = []\n",
        "    val_aucs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            preds = outputs.detach().cpu().numpy() > 0.5\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        train_accs.append(train_acc)\n",
        "        train_auc = roc_auc_score(all_labels, all_preds)\n",
        "        train_aucs.append(train_auc)\n",
        "\n",
        "        val_loss, val_f1, val_acc, val_auc = evaluate_model(model, val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        val_aucs.append(val_auc)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Val F1: {val_f1}, Val ACC: {val_acc}, Val AUC: {val_auc}')\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    test_loss, test_f1, test_acc, test_auc = evaluate_model(model, test_loader)\n",
        "    print(f'Test Loss: {test_loss}, Test F1: {test_f1}, Test ACC: {test_acc}, Test AUC: {test_auc}')\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, test_loss, test_f1, test_acc, test_auc\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = outputs.detach().cpu().numpy() > 0.5\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = accuracy_score(all_labels, all_preds)\n",
        "    val_auc = roc_auc_score(all_labels, all_preds)\n",
        "    val_f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    return val_loss, val_f1, val_acc, val_auc\n"
      ],
      "metadata": {
        "id": "cHX-7-Dx_C9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def plot_metrics(train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, dropout_values):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # Plot Dropout value\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, dropout_values, 'b-', label='Dropout')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dropout')\n",
        "    plt.title('Dropout Schedule')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ACC vs EPOCH\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, train_accs, 'r-', label='Train ACC')\n",
        "    plt.plot(epochs, val_accs, 'g-', label='Val ACC')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Bar plot of precision, recall, AUC, ACC\n",
        "    labels = ['Train', 'Val']\n",
        "    metrics = ['Precision', 'Recall', 'AUC', 'ACC']\n",
        "    train_metrics = [train_precision, train_recall, train_auc, train_acc]\n",
        "    val_metrics = [val_precision, val_recall, val_auc, val_acc]\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    rects1 = ax.bar(x - width/2, train_metrics, width, label='Train')\n",
        "    rects2 = ax.bar(x + width/2, val_metrics, width, label='Val')\n",
        "\n",
        "    ax.set_xlabel('Metrics')\n",
        "    ax.set_ylabel('Scores')\n",
        "    ax.set_title('Metrics by dataset')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend()\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ss6nWqnjUzhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SLFENDModel().to(device)\n",
        "\n",
        "\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, test_loss, test_f1, test_acc, test_auc = train_model(model, train_loader, val_loader, test_loader)\n",
        "\n",
        "# Example dropout values\n",
        "dropout_values = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "# Plot metrics\n",
        "plot_metrics(train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, dropout_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "di4KxZRfQk8_",
        "outputId": "2a445b23-64b4-43cf-eb5d-bbc4b9fadb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'criterion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e15debba3f37>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_aucs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_aucs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Example dropout values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9f067689636c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, test_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtrain_aucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mval_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9f067689636c>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, f1_score\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, test_loader, num_epochs=10, learning_rate=2e-5):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    best_f1 = 0\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    train_aucs = []\n",
        "    val_aucs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            preds = outputs.detach().cpu().numpy() > 0.5\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        train_accs.append(train_acc)\n",
        "        train_auc = roc_auc_score(all_labels, all_preds)\n",
        "        train_aucs.append(train_auc)\n",
        "\n",
        "        val_loss, val_f1, val_acc, val_auc = evaluate_model(model, val_loader, criterion)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        val_aucs.append(val_auc)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Val F1: {val_f1}, Val ACC: {val_acc}, Val AUC: {val_auc}')\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    test_loss, test_f1, test_acc, test_auc = evaluate_model(model, test_loader, criterion)\n",
        "    print(f'Test Loss: {test_loss}, Test F1: {test_f1}, Test ACC: {test_acc}, Test AUC: {test_auc}')\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, test_loss, test_f1, test_acc, test_auc\n",
        "\n",
        "def evaluate_model(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = outputs.detach().cpu().numpy() > 0.5\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = accuracy_score(all_labels, all_preds)\n",
        "    val_auc = roc_auc_score(all_labels, all_preds)\n",
        "    val_f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    return val_loss, val_f1, val_acc, val_auc\n",
        "\n",
        "def plot_metrics(train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, dropout_values):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    # Plot Dropout value\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, dropout_values, 'b-', label='Dropout')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dropout')\n",
        "    plt.title('Dropout Schedule')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ACC vs EPOCH\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, train_accs, 'r-', label='Train ACC')\n",
        "    plt.plot(epochs, val_accs, 'g-', label='Val ACC')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs Epoch')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Bar plot of precision, recall, AUC, ACC\n",
        "    labels = ['Train', 'Val']\n",
        "    metrics = ['Precision', 'Recall', 'AUC', 'ACC']\n",
        "    train_metrics = [train_precision, train_recall, train_auc, train_acc]\n",
        "    val_metrics = [val_precision, val_recall, val_auc, val_acc]\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    rects1 = ax.bar(x - width/2, train_metrics, width, label='Train')\n",
        "    rects2 = ax.bar(x + width/2, val_metrics, width, label='Val')\n",
        "\n",
        "    ax.set_xlabel('Metrics')\n",
        "    ax.set_ylabel('Scores')\n",
        "    ax.set_title('Metrics by dataset')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend()\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SLFENDModel().to(device)\n",
        "\n",
        "\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, test_loss, test_f1, test_acc, test_auc = train_model(model, train_loader, val_loader, test_loader)\n",
        "\n",
        "# Example dropout values\n",
        "dropout_values = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "# Plot metrics\n",
        "plot_metrics(train_losses, val_losses, train_accs, val_accs, train_aucs, val_aucs, dropout_values)\n"
      ],
      "metadata": {
        "id": "Y9NQnORxYqWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}